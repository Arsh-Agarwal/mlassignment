{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e17442-cfb3-4625-8d9e-02d8479447df",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f8a2f61-f8d1-4235-b4a5-c6c878354c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598e3b6-9df9-49de-9ce2-ee577ee95800",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6df59e4-65f4-478b-adfc-352947f66243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date  precipitation  temp_max  temp_min  wind  weather\n",
      "0     2012-01-01            0.0      12.8       5.0   4.7  drizzle\n",
      "1     2012-01-02           10.9      10.6       2.8   4.5     rain\n",
      "2     2012-01-03            0.8      11.7       7.2   2.3     rain\n",
      "3     2012-01-04           20.3      12.2       5.6   4.7     rain\n",
      "4     2012-01-05            1.3       8.9       2.8   6.1     rain\n",
      "...          ...            ...       ...       ...   ...      ...\n",
      "1456  2015-12-27            8.6       4.4       1.7   2.9     rain\n",
      "1457  2015-12-28            1.5       5.0       1.7   1.3     rain\n",
      "1458  2015-12-29            0.0       7.2       0.6   2.6      fog\n",
      "1459  2015-12-30            0.0       5.6      -1.0   3.4      sun\n",
      "1460  2015-12-31            0.0       5.6      -2.1   3.5      sun\n",
      "\n",
      "[1461 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset.csv')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0faa59-8b2d-4e6b-a552-be1e23cc5c41",
   "metadata": {},
   "source": [
    "# Split in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28837dab-6d3c-4678-a4dc-f4d6bbb34ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_input = dataset.iloc[:, 1:-1]\n",
    "tot_output = dataset.iloc[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tot_input, tot_output, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90fe016a-2846-47f9-9c0c-cdacdf77e0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drizzle' 'rain' 'sun' 'snow' 'fog']\n"
     ]
    }
   ],
   "source": [
    "print(tot_output.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74cd788-afc6-4738-ae4a-38480360c476",
   "metadata": {},
   "source": [
    "# Entropy Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97b0519d-784a-4462-a06b-e4bd97511981",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropyDT:\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.root_node = None\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, data, target, depth):\n",
    "            self.data = data\n",
    "            self.target = target\n",
    "            self.depth = depth\n",
    "            self.children = {}\n",
    "            self.split_attribute = None\n",
    "            self.is_leaf = False\n",
    "            self.label = None\n",
    "\n",
    "    def entropy(self, target):\n",
    "        values, counts = np.unique(target, return_counts=True)\n",
    "        probabilities = counts / len(target)\n",
    "        entropy_value = -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "        return entropy_value\n",
    "\n",
    "    def information_gain(self, data, target, attribute):\n",
    "        unique_values = data[attribute].unique()\n",
    "        entropy_before = self.entropy(target)\n",
    "        entropy_after = 0\n",
    "\n",
    "        for value in unique_values:\n",
    "            subset_indices = data[attribute] == value\n",
    "            subset_target = target[subset_indices]\n",
    "            entropy_after += len(subset_target) / len(target) * self.entropy(subset_target)\n",
    "\n",
    "        gain = entropy_before - entropy_after\n",
    "        return gain\n",
    "\n",
    "    def id3_algorithm(self, node):\n",
    "        unique_labels = node.target.unique()\n",
    "\n",
    "        if len(unique_labels) == 1:\n",
    "            node.is_leaf = True\n",
    "            node.label = unique_labels[0]\n",
    "            return\n",
    "\n",
    "        if node.depth >= self.max_depth:\n",
    "            node.is_leaf = True\n",
    "            node.label = unique_labels[0]  # Choose the most common label at this leaf\n",
    "            return\n",
    "\n",
    "        best_gain = 0\n",
    "        best_attribute = None\n",
    "\n",
    "        for attribute in node.data.columns:\n",
    "            gain = self.information_gain(node.data, node.target, attribute)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_attribute = attribute\n",
    "\n",
    "        if best_attribute is None:\n",
    "            node.is_leaf = True\n",
    "            node.label = unique_labels[0]  # Choose the most common label at this leaf\n",
    "            return\n",
    "\n",
    "        node.split_attribute = best_attribute\n",
    "        unique_values = node.data[best_attribute].unique()\n",
    "\n",
    "        for value in unique_values:\n",
    "            subset_indices = node.data[best_attribute] == value\n",
    "            subset_data = node.data.loc[subset_indices].drop(columns=[best_attribute])\n",
    "            subset_target = node.target[subset_indices]\n",
    "\n",
    "            child_node = self.Node(subset_data, subset_target, node.depth + 1)\n",
    "            node.children[value] = child_node\n",
    "\n",
    "            self.id3_algorithm(child_node)\n",
    "\n",
    "    def fit(self, data, target):\n",
    "        self.root_node = self.Node(data, target, 0)\n",
    "        self.id3_algorithm(self.root_node)\n",
    "\n",
    "    def predict_instance(self, node, instance):\n",
    "        if node.is_leaf:\n",
    "            return node.label\n",
    "        else:\n",
    "            value = instance[node.split_attribute]\n",
    "            if value in node.children:\n",
    "                return self.predict_instance(node.children[value], instance)\n",
    "            else:\n",
    "                return node.target.mode().iloc[0]\n",
    "\n",
    "    def predict(self, instances_df):\n",
    "        predictions = []\n",
    "    \n",
    "        for index, row in instances_df.iterrows():\n",
    "            instance_dict = row.to_dict()\n",
    "            prediction = self.predict_instance(self.root_node, instance_dict)\n",
    "            predictions.append(prediction)\n",
    "    \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32190bfe-b161-46f4-b54b-86c622af0dbe",
   "metadata": {},
   "source": [
    "# Gini Index Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58bd8ac2-1ee9-40c7-9311-3f6480fac6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GiniDT:\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.root_node = None\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, data, target, depth):\n",
    "            self.data = data\n",
    "            self.target = target\n",
    "            self.depth = depth\n",
    "            self.children = {}\n",
    "            self.split_attribute = None\n",
    "            self.is_leaf = False\n",
    "            self.label = None\n",
    "\n",
    "    def gini_index(self, target):\n",
    "        values, counts = np.unique(target, return_counts=True)\n",
    "        probabilities = counts / len(target)\n",
    "        gini = 1 - np.sum(probabilities**2)\n",
    "        return gini\n",
    "\n",
    "    def gini_index_split(self, data, target, attribute):\n",
    "        unique_values = data[attribute].unique()\n",
    "        gini_before = self.gini_index(target)\n",
    "        gini_after = 0\n",
    "\n",
    "        for value in unique_values:\n",
    "            subset_indices = data[attribute] == value\n",
    "            subset_target = target[subset_indices]\n",
    "            gini_after += len(subset_target) / len(target) * self.gini_index(subset_target)\n",
    "\n",
    "        return gini_before - gini_after\n",
    "\n",
    "    def decision_tree_algorithm(self, node):\n",
    "        unique_labels = node.target.unique()\n",
    "\n",
    "        if len(unique_labels) == 1:\n",
    "            node.is_leaf = True\n",
    "            node.label = unique_labels[0]\n",
    "            return\n",
    "\n",
    "        if node.depth >= self.max_depth:\n",
    "            node.is_leaf = True\n",
    "            node.label = unique_labels[0]  # Choose the most common label at this leaf\n",
    "            return\n",
    "\n",
    "        best_gini_gain = 0\n",
    "        best_attribute = None\n",
    "\n",
    "        for attribute in node.data.columns:\n",
    "            gini_gain = self.gini_index_split(node.data, node.target, attribute)\n",
    "            if gini_gain > best_gini_gain:\n",
    "                best_gini_gain = gini_gain\n",
    "                best_attribute = attribute\n",
    "\n",
    "        if best_attribute is None:\n",
    "            node.is_leaf = True\n",
    "            node.label = unique_labels[0]  # Choose the most common label at this leaf\n",
    "            return\n",
    "\n",
    "        node.split_attribute = best_attribute\n",
    "        unique_values = node.data[best_attribute].unique()\n",
    "\n",
    "        for value in unique_values:\n",
    "            subset_indices = node.data[best_attribute] == value\n",
    "            subset_data = node.data.loc[subset_indices].drop(columns=[best_attribute])\n",
    "            subset_target = node.target[subset_indices]\n",
    "\n",
    "            child_node = self.Node(subset_data, subset_target, node.depth + 1)\n",
    "            node.children[value] = child_node\n",
    "\n",
    "            self.decision_tree_algorithm(child_node)\n",
    "\n",
    "    def fit(self, data, target):\n",
    "        self.root_node = self.Node(data, target, 0)\n",
    "        self.decision_tree_algorithm(self.root_node)\n",
    "\n",
    "    def predict_instance(self, node, instance):\n",
    "        if node.is_leaf:\n",
    "            return node.label\n",
    "        else:\n",
    "            value = instance[node.split_attribute]\n",
    "            if value in node.children:\n",
    "                return self.predict_instance(node.children[value], instance)\n",
    "            else:\n",
    "                return node.target.mode().iloc[0]\n",
    "\n",
    "    def predict(self, instances_df):\n",
    "        predictions = []\n",
    "\n",
    "        for index, row in instances_df.iterrows():\n",
    "            instance_dict = row.to_dict()\n",
    "            prediction = self.predict_instance(self.root_node, instance_dict)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648dea5-2014-4650-a1fc-113c76fd3385",
   "metadata": {},
   "source": [
    "# Train Entropy Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21858250-11d9-413e-8a57-9a1038db33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 3\n",
    "tree = EntropyDT(max_depth)\n",
    "# tree = GiniDT(max_depth)\n",
    "tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c75513a-8a28-4ba0-a10b-d0903e173b11",
   "metadata": {},
   "source": [
    "# Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b152eeb-38e0-42c4-9840-923829c636f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  77.47440273037543 %\n"
     ]
    }
   ],
   "source": [
    "# Example prediction\n",
    "predictions = tree.predict(x_test)\n",
    "total = len(predictions)\n",
    "correct = 0\n",
    "for i in range(total):\n",
    "    if(predictions[i] == y_test.iloc[i]): correct+=1\n",
    "\n",
    "print(\"Accuracy: \", correct*100/total, \"%\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
